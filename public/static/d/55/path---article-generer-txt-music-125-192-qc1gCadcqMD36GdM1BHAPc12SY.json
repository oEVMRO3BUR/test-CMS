{"data":{"article":{"frontmatter":{"title":"Générer du texte et de la musique avec les modèles n-grammes","author":"Felix","excerpt":"Les n-grammes, modèles permettant de prédire des mots faisant suite à d'autres suites de mots","date":"30/09/2019","tags":["machine learning"],"illustration":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAC4jAAAuIwF4pT92AAACgElEQVQoz2NgEJFjtwmJmLxmztHrpx68ffD667P33378/nPn2ee3H378////zvPPy44+OnT99Zfvv//9Awr8+/v/f/3GcxUrDzKwy+kyqFrmT1oGEoZIgsk7Tz8dPP983c7Dbz98nb/vdtbcg9vOPP7188/Hb/+PX7i67/zdlGk7GNj4xNk4BXlVrQ5dfvn3978fP3///fv3y5df9x9+2n3otqiK8eylW7tXng1rXtW86OjNh++uP/igbORkE5S28cAdBhY+cWZxnfD0tnv33/78+ef7j19///37/v3X75//L1y6z69g6hdXkd680j9/etP0XcdOP7x69YGotLKUtuXE+esZ2CTVw9Lbz5y5AXTq3MWrZi9cBWT8+v0bSF6/89TAJT4ppyUwrjI6f/qSlUd+fP0FFPdKyMvomAe0hkHdzCM8tqimqat9wkzPwLjsguqdew7uP3JqxaqtR05c1LEP9g1KLMhr2Lzh9I+v/y5cvDxt5tzaBVt6tl18//kHA4+wtLC4griUCq+wtKq2qbSKvpCcloG1h6qWiaNHqKNbgKScuo6BdUJyXlff9ODIZH4JFS0dw6beWTPnr2IAAhVNAyk5ZQYGVl4hKVZOPnY+MSFpNUYWDh5+EWFxOSk5VU5eYV4hMaBKPiFJfmEpNnYuASFxFg4BkGZ2Hn42PmFuPlFmZlYmTj5GFjZGJhagAkZmdnZ+MQYmVmZWThYOXiZmNmZ2HlZ2LqAyTj4xIIMBApiYWVjYOIEMRmZWVi4BJiZWDi4BPXNnRUMbIUUtoCuYWDkZmZgZWdlBahiZ2Lj4gFwGOAAKMUIBSJRfVEpaQQ3kLj4hZk5+uCq4agZGJgBgxwlfj/QMwQAAAABJRU5ErkJggg==","aspectRatio":1.83206106870229,"src":"/static/656235176b2d53f8ee82a01d0a2b3bbc/af144/cover.png","srcSet":"/static/656235176b2d53f8ee82a01d0a2b3bbc/7c0ed/cover.png 200w,\n/static/656235176b2d53f8ee82a01d0a2b3bbc/647de/cover.png 400w,\n/static/656235176b2d53f8ee82a01d0a2b3bbc/af144/cover.png 800w,\n/static/656235176b2d53f8ee82a01d0a2b3bbc/ba299/cover.png 1200w,\n/static/656235176b2d53f8ee82a01d0a2b3bbc/9ecf6/cover.png 1600w,\n/static/656235176b2d53f8ee82a01d0a2b3bbc/ec873/cover.png 1920w","sizes":"(max-width: 800px) 100vw, 800px"}}}},"htmlAst":{"type":"root","children":[{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ouvrez votre téléphone et commencez à taper un message. \"Je vais être en\". Il y a de fortes chances que votre système de recommandation affiche le mot \"retard\". Félicitations vous venez très probablement d'utiliser un modèle n-gramme. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Mais en quoi ça consiste exactement un modèle n-gramme?"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"1. Un peu de théorie (désolé pour les maths)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"1.1 Représenter le langage"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Un modèle, comme son nom l'indique, sert à *modéliser. En l'occurence ce que l'on cherche ici à modéliser c'est le langage. On peut considérer que chaque phrase a une *"},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"probabilité d'apparition"}]},{"type":"text","value":" dans l'ensemble des phrases possibles, constitués des mots de la langue française. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Mais nous on cherche à générer du texte non? Pas à modéliser la langue?\nC'est vrai, dans l'idée. Mais comme en physique où comprendre comment une planète se déplace permet de prédire sa position future, modéliser la langue permet de créer des structures \"cohérentes\" avec cette dernière."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Le problème... c'est qu'il est impossible de connaître toutes les phrases existantes, et surtout impossible de connaître leur fréquence d'apparition. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une solution serait alors de modéliser la probabilité d'une phrase en fonction de la probabilité conditionnelle des mots la constituant. C'est à dire prédire l'apparition d'un mot n en fonction des probabilité d'apparition de tous les mots de n-1 à 1."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"*Par exemple pour une phrase s = \"Je suis fatigué.\" "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"P(s) = P(\"je\") * P(\"suis\" | je) * P(\"fatigué\" | (\"suis\" |\"je\"))"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour plus d'informations: "},{"type":"element","tagName":"a","properties":{"href":"https://fr.wikipedia.org/wiki/Formule_des_probabilit%C3%A9s_compos%C3%A9es"},"children":[{"type":"text","value":"Les probabilités composées"}]},{"type":"text","value":"*"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"1.2 Markov à la rescousse!"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Malheureusement cela ne nous aide pas énormément. En effet, que se passe-t-il si l'on cherche à calculer les probabilités des phrases suivantes:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Je suis fatigué"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Il se fait tard et je suis fatigué"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"La journée a été longue et je suis fatigué"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Il faudra connaître à chaque fois la probabilité de \"fatigué\" "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"sachant"}]},{"type":"text","value":" tous les mots précédents. Ce qui impliquerait d'avoir une base énorme de texte pour pouvoir calculer tous les cas particuliers un par un. Et encore, face à une phrase non présente dans l'ensemble d'apprentissage, cela ne marcherait pas."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Cependant"}]},{"type":"text","value":" (et là tout devient facile)."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On peut remarquer que dans les trois phrases les mots précédant \"fatigué\" sont toujours \"je\" et \"suis\"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et bien le principe du modèle n-gramme est de considérer que cet \"historique\" de mots précédant \"fatigué\" peut être approché par un sous ensemble de taille "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"n"}]},{"type":"text","value":" de cet historique. On peut alors parler de chaîne de Markov d'ordre n - 1. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Une hypothèse de Markov est le fait de considérer que certaines suites d'événements peuvent être expliquées soit de façon complètement indépendantes soit en utilisant un historique réduit. On parle  d'ordre n - 1 car on utilise les n - 1 mots précédant le mot n pour prédire la probabilité de ce dernier.\nPour plus d'informations "},{"type":"element","tagName":"a","properties":{"href":"https://en.wikipedia.org/wiki/Markov_chain"},"children":[{"type":"text","value":"Les chaines de Markov"}]}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Mettons que l'on prenne "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"n = 2"}]},{"type":"text","value":", le calcul de la probabilité d'apparition de \"fatigué\" dans la phrase \"Il se fait tard et je suis\" sera tout simplement P(\"fatigué\" | \"suis\")."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ce que l'on va alors chercher à faire, c'est connaître les fréquences d'apparition de tous les bigrammes de l'ensemble d'apprentissage.\nReprenons nos phrases de tout à l'heure et ajoutons la phrase:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"\"Je m'appelle Tom et je vais dans l'espace.\""}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Nous pouvons alors calculer les probabilités des bigrammes contenant par exemple le mot \"je\": "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"S[je] = {\n    P(suis | je) = 3/5\n    P(vais | je) = 1/5\n    P(m'appelle | je) = 1/5\n}"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Cela revient à dire que si l'on rencontre le mot \"je\" dans une phrase, il y a 60% de chances qu'il soit suivi du mot \"suis\", et 20% de chances qu'il soit suivi de \"vais\" ou \"m'appelle\". "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Le système de génération de texte est alors enfantin. En prenant les probabilités cumulées du bigramme ci dessus, avec X le mot à prédire, on peut constuire les intervalles de prédiction pour chaque mot."}]},{"type":"text","value":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"type":"element","tagName":"table","properties":{},"children":[{"type":"element","tagName":"thead","properties":{},"children":[{"type":"element","tagName":"tr","properties":{},"children":[{"type":"element","tagName":"th","properties":{},"children":[{"type":"text","value":"X"}]},{"type":"element","tagName":"th","properties":{},"children":[{"type":"text","value":"P(X)"}]},{"type":"element","tagName":"th","properties":{},"children":[{"type":"text","value":"Cumulé"}]},{"type":"element","tagName":"th","properties":{},"children":[{"type":"text","value":"Intervalle"}]}]}]},{"type":"element","tagName":"tbody","properties":{},"children":[{"type":"element","tagName":"tr","properties":{},"children":[{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"Rien"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"Vide"}]}]},{"type":"element","tagName":"tr","properties":{},"children":[{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"\"suis\""}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0.60"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0.60"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"[0;0.60]"}]}]},{"type":"element","tagName":"tr","properties":{},"children":[{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"\"vais\""}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0.20"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0.80"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"]0.60;0.80]"}]}]},{"type":"element","tagName":"tr","properties":{},"children":[{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"\"m'appelle\""}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"0.20"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"1"}]},{"type":"element","tagName":"td","properties":{},"children":[{"type":"text","value":"]0.80;1]"}]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Il suffit de tirer un nombre aléatoire "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"y"}]}]},{"type":"text","value":" entre 0 et 1, et de choisir le mot tel que "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"y"}]}]},{"type":"text","value":" soit compris dans l'intervalle du mot."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Ex: si je tire 0.70, on a  0.60 < 0.70 < 0.80. Le mot généré sera donc \"vais\"."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Bien sûr, prédire un mot en prenant seulement en compte le mot d'avant est assez réducteur et le résultat sera souvent assez limité, mais dès que l'on utilise des valeurs de "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"n"}]},{"type":"text","value":" égales à 4 ou 5, la cohérence du texte généré augmente. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Attention ! Plus n augmente, plus le contenu généré risquera de coller au texte originel et de ne plus rien proposer d'original. C'est ce qu'on appelle communément en machine learning l'overfitting."}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Il faut donc faire attention en choississant n, on pourra se permettre des valeurs plus élevées sur des corpus d'entraînement plus gros. Mais généralement les 4-grammes (comme un breton à 9h du matin) ou les 5-grammes donnent des résultats corrects."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"1.3 Cas d'usage"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une brève parenthèse avant de passer au code lui même, pour parler des cas d'usages 'réels' de ces modèles.\nLes modèles n-grammes sont utilisés plus souvent qu'on ne peut le penser. Notamment en complétion des algorithmes de reconnaissance automatique du langage écrit ou parlé, ou même encore pour aider à la reconnaissance de patterns lors du séquençage ADN."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Imaginez un logiciel de reconnaissance de caractères (OCR) à qui l'on donnerait la phrase suivante en entrée \"J'ai mangé des pêches\", et que le dernier mot fort mal écrit, soit reconnu à 70% comme \"bêches\" et à 30% comme pêches. Notre algorithme pourra alors tenter de s'appuyer sur un modèle 4-grammes (toujours aucun rapport avec le chouchen), pour infirmer sa déduction puisque le mot bêche n'apparait jamais après la séquence \"ai mangé des\"."}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"En réalité, ce type de modèle est loin de s'appliquer simplement aux mots, et peut être utilisé pour toute suite logique de n éléments au sein d'un ensemble, cela peut être des lettres (pour prédire caractère par caractère ce qui va être écrit), avec des sons, des suites de pixels... Le système est simple, les possibilités nombreuses."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ces bases théoriques étant posées, et le principe de génération par n-gramme clair comme de l'eau de roche, passons maintenant à une partie plus amusante : la pratique."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"2. Implémentation en python"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Est décrite ci-dessous une implémentation assez naïve du modèle et en pseudo code. Pour ceux voulant aller plus loin ou tester eux même, le code complet avec des méthodes pour preprocesser le texte est disponible "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/Tyrannas/n-grams-experiments"},"children":[{"type":"text","value":"ici"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Résumons donc ce dont nous avons besoin pour faire fonctionner notre modèle:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Un corpus d'apprentissage pour calculer les probabilités."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Une méthode d'apprentissage qui, pour chaque n-gramme, calculera lesdites probabilités."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Une méthode de génération une fois l'apprentissage terminé."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"2.1 Les structures de données"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"La première question qui se pose est celle de la représentation des n-grammes. Pour rappel, il faut pouvoir associer des probabilités pour le nième mot de suivre n - 1 mots."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une solution est donc, pour chacune de ces suites de n - 1 mots (que nous pourrons appeler ici (n-1)-gramme), de tenir un dictionnaire de mots à 'prédire' associant le mot à sa probabilité de suivre la suite. Ainsi pour "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"n = 4"}]},{"type":"text","value":" la suite 'homme sois plus' aura pour dictionnaire:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"{\n    'violent': 0.33,\n    'puissant': 0.33,\n    'ardent': 0.33\n}"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Dans les faits, l'apprentissage se fera au fur et à mesure, il faudra donc être en mesure de recalculer les probabilités si l'on ajoute un nouveau mot au dictionnaire. Or comment calculer cette probabilité?"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"P(mot) = nb_occurences_mot / nb_total_occurences"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour cela, on rajoute aussi la notion d'occurence dans le dictionnaire:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"{\n    'violent': {'count': 2, 'proba': 0.33},\n    'puissant': {'count': 2, 'proba': 0.33},\n    'ardent': {'count': 2, 'proba': 0.33}\n}"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et on gardera en parallèle pour chaque suite de mots un compte du total des count du dictionnaire (qui pourrait aussi être recalculé à chaque fois)."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ainsi, si l'on rencontre à nouveau le mot 'violent' après la suite \"homme sois plus\", on obtiendra:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"{\n    'violent': {'count': 3, 'proba': 0.43},\n    'puissant': {'count': 2, 'proba': 0.29},\n    'ardent': {'count': 2, 'proba': 0.29}\n}"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Il suffit de procéder de manière identique pour chaque (n-1)-gramme unique trouvé dans le texte."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"2.1 L'apprentissage"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On utilisera ici deux classes:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"une classe NGram chargée de la mise à jour du dictionnaire abordé plus tôt. Nous créerons donc une instance de NGram par (n-1)-gramme trouvé."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"une classe Model chargée de l'apprentissage global et du management des instances NGram."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une fois cela établi l'implémentation est assez simple."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"python"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-python"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-python"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"class"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","class-name"]},"children":[{"type":"text","value":"NGram"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"def"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"("}]},{"type":"text","value":"self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n        self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"."}]},{"type":"text","value":"words_to_predict "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"="}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"{"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"}"}]},{"type":"text","value":"\n    \n    "},{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"def"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"add_word"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"("}]},{"type":"text","value":"self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":","}]},{"type":"text","value":" word"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# si le mot existe déjà on incrémente son count"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# sinon on créé le mot avec un count de 1"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on recalcule les probas"}]},{"type":"text","value":"\n    \n    "},{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"def"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"compute_proba"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"("}]},{"type":"text","value":"self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# total_count = somme des count de chaque mot de self.words_to_predict"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# pour chaque mot de self.words_to_predict:"}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# sa proba vaut son propre count / total_count"}]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"python"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-python"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-python"]},"children":[{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"class"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","class-name"]},"children":[{"type":"text","value":"Model"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"def"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"__init__"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"("}]},{"type":"text","value":"self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":","}]},{"type":"text","value":" n"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# n la taille du n-gramme"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# comme on prendra des suites de mots de taille n - 1, pour s'éviter de réécrire n - 1 on assigne self.n = n - 1"}]},{"type":"text","value":"\n        self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"."}]},{"type":"text","value":"n "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"="}]},{"type":"text","value":" n "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"-"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","number"]},"children":[{"type":"text","value":"1"}]},{"type":"text","value":"\n        self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"."}]},{"type":"text","value":"ngrams "},{"type":"element","tagName":"span","properties":{"className":["token","operator"]},"children":[{"type":"text","value":"="}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"{"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"}"}]},{"type":"text","value":"\n    \n    "},{"type":"element","tagName":"span","properties":{"className":["token","keyword"]},"children":[{"type":"text","value":"def"}]},{"type":"text","value":" "},{"type":"element","tagName":"span","properties":{"className":["token","function"]},"children":[{"type":"text","value":"train"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":"("}]},{"type":"text","value":"self"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":","}]},{"type":"text","value":" texte"},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":")"}]},{"type":"element","tagName":"span","properties":{"className":["token","punctuation"]},"children":[{"type":"text","value":":"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on sépare le texte en tableau de mots en splittant sur les espaces"}]},{"type":"text","value":"\n        "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# pour i = self.n jusqu'à la fin du texte:"}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on prend self.n mots à partir de i"}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on créé un identifiant composé de ces mots qui nous servira à identifier ce ngramme dans le dictionnaire self.ngrams "}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on créé self.ngrams[id] = Ngram() s'il n'existe pas"}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# on utilise la méthode add_word du ngramme nouvellement créé en lui passant le mot suivant les self.n mots:"}]},{"type":"text","value":"\n            "},{"type":"element","tagName":"span","properties":{"className":["token","comment"]},"children":[{"type":"text","value":"# ==> self.ngrams[id].addword[texte[i + self.n + 1]]"}]}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et voilà, une fois le texte parcouru en entier par la méthode train, toutes vos probabilités devraient être calculées et il ne reste plus qu'à générer du texte."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"2.3 La génération"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Reprenons nos deux classes et ajoutons les méthodes de génération:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"la classe NGram a besoin de tirer un nombre aléatoire et de renvoyer un mot."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"la classe Model elle doit sélectionner le bon objet Ngram en fonction de la séquence d'entrée pour générer un mot."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"python\nclass NGram:\n...\ndef generate(self):\n# on tire un nombre entre 0 et 1\n# on sélectionne le mot dont la probabilité cumulée est supérieure à ce nombre et on renvoie le mot"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"class Model:\ndef generate(self, words):\n# on créé un id à partir des mots\n# on teste si cet id est enregistré dans les ngrammes\n# si oui on demande à ce ngramme de générer un mot"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et voilà, c'était extrêmement simple. On peut ensuite modifier un peu la méthode generate de la classe Model pour générer automatiquement de plus longues suites de mots en créant à chaque fois une nouvelle séquence en enlevant le premier mot de la séquence d'avant, et en rajoutant le mot qui vient d'être prédit."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"\"is Major Tom\" ==> \"to\"\n\"Major Tom to\" ==> \"Ground\"\n\"Tom to Ground\" ==> \"Control\"\n\"to Ground Control\" ==> ...\netc."}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et maintenant testons un peu ce modèle avec des exemples concrets."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"3. Les exemples"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On utilise pour la suite différents corpus, en l'occurence les trois mousquetaires en français, et le seigneur des anneaux intégral en anglais.\nOn génèrera aléatoirement 2 phrases à chaque fois, en ne donnant pas de mot de départ, mais en prenant au hasard un n-gramme parmi ceux appris."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"3.1 Les trois mousquetaires"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ce texte présente trois difficultés: "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"c'est un texte qu'on peut qualifier de littérature \"classique\" d'un siècle passé, et les tournures sont parfois un peu compliquées et à rallonge. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"le français est moins facile à générer que l'anglais du fait de ses caractères additionnels, et demande donc un peu plus de pré-traitement pour être utilisable"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"le texte ne fait \"que\" 250 000 mots, ce qui limite l'apparition de longue chaines de mots identiques et le risque de coller trop au texte est donc augmenté."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=3"}]},{"type":"text","value":" (on se base donc sur deux mots d'historique):"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"L'une était un signal. Désormais il faut être libre et si vous avez eu tort.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=4"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Athos porthos et aramis se placèrent à une table et se mit à table mangea peu et ne but que de l'eau. À mon tour.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=5"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Le mot est un peu dur. Vous avez baisé la main de la porte.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"C'est vous d'artagnan c'est vous athos dit le jeune homme je vous l'avoue d'autant mieux mon cher monsieur bonacieux que je vois qu'on ne peut rien vous cacher. Enfin tout à coup une voix pleine de douceur et de majesté.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On peut dores et déjà saisir un problème inhérent aux n-grammes, s'ils respectent bien la syntaxe, les phrases n'ont pas toujours énormément de cohérence entre elles."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"3.2 Le seigneur des anneaux"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Ce texte est un peu plus long - 800 000 mots - (et les corpus utilisés en machine learning peuvent dépasser le milliard de mot, 800 000 reste donc assez faible.)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=3"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Because an old inn that is the spirit of mordor and became separated from the beginning of their cavalry, turned and went after him. All's clear now.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une auberge tueuse."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Skulls and bones black in cinders lie beneath the roots of the food i send with you. Dreadful as the valley.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et un repas peu engageant."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=4"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Fierce voices rose up to greet it from across the valley. When dinner was over they began to tell on him as he swayed it from side to side the king's party came up under the lowering clouds with crimson.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une belle soirée."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Peace and freedom do you say. Let me get my hands on you.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=5"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Not very near and yet too near it seems. As it was he had a desperate fight before he got free.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"Yet at the last beren was slain by the same orcs whom you destroyed'. That we now know too well.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Et enfin un bel exemple d'overfitting, le modèle a ressorti exactement le texte mot pour mot avec cet exemple:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"\"An author cannot of course remain wholly unaffected by his experience but the ways in which a storygerm uses the soil of experience are extremely complex and attempts to define the process are at best guesses from evidence that is inadequate and ambiguous.\""}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"La raison est très probablement que le registre que l'on trouve ici (celui de l'écriture) est assez différent du reste du livre qui tend plus vers le fantastique et le guerrier. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On voit donc que notre modèle basique peut produire des textes certes un peu étranges, mais presque tout le temps avec un assez bon respect de la syntaxe. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour terminer, après avoir testé la génération sur du texte, pourquoi ne pas la tester sur de la musique?"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"3.3 Tablatures de guitare"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Tout comme pour la génération de mots, la génération de musique nécessite d'avoir un corpus d'apprentissage. Diverses solutions existent, mais l'une des plus simples à mettre en oeuvre reste de se baser sur des tablatures de guitares, puisque des milliers de tablatures sont disponibles "},{"type":"element","tagName":"a","properties":{"href":"https://www.ultimate-guitar.com/explore"},"children":[{"type":"text","value":"sur ultimate guitar"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Une tablature de guitare est un fichier texte représentant les six cordes de l'instrument, et pour chacune de ces cordes les endroits où il faut appuyer à un instant t:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/39d051fcf2c7520828dac4a721296eee/ec5f3/tab_example.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 700px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 18.842530282637952%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABJ0AAASdAHeZh94AAAAjklEQVQY001PWQ5DIQj0/ufsS+wTZPEAlHFLPwg4MgvFxwjpPZg5VDV6zqskWmthZvm/Zne/O8DBATZSAwWsvO8bInIFeAtiPpiITjIRhalN0W/yPs+zg9gylh7luKBbLh5BkJhXhyE1miTb5J5YrXWagDvDMEVxHzcyCgL/73OK2z5t7ytE9+lICFNJ7g8FGi/ldFWvTgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"image tableau 1!","title":"","src":"/static/39d051fcf2c7520828dac4a721296eee/a8200/tab_example.png","srcSet":["/static/39d051fcf2c7520828dac4a721296eee/52d5c/tab_example.png 175w","/static/39d051fcf2c7520828dac4a721296eee/1bae2/tab_example.png 350w","/static/39d051fcf2c7520828dac4a721296eee/a8200/tab_example.png 700w","/static/39d051fcf2c7520828dac4a721296eee/ec5f3/tab_example.png 743w"],"sizes":["(max-width:","700px)","100vw,","700px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Le plus gros du travail a été de récupérer les tablatures, de les parser, et de les nettoyer. (Mais ceci n'étant pas le sujet de cet article, tous les scripts sont disponibles "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/Tyrannas/n-grams-experiments/tree/master/tabs/scripts"},"children":[{"type":"text","value":"ici"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"L'étape manquante consiste juste à définir ce qu'est un \"mot\" lorsqu'on parle d'une tablature. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On prendra ici toutes les notes jouées au même moment sur les différentes cordes. Cela peut donc être représenté par un tableau de six éléments:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"['-', '0', '0', '-',a '2', '-']"}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"blockquote","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"Ce tableau correspondrait à la portion en rouge sur la tablature du dessus:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"a","properties":{"className":["gatsby-resp-image-link"],"href":"/static/8642531b455ff7196ff3e4253ece2344/ec5f3/tab_example2.png","style":"display: block","target":"_blank","rel":["noopener"]},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-wrapper"],"style":"position: relative; display: block; margin-left: auto; margin-right: auto;  max-width: 700px;"},"children":[{"type":"text","value":"\n    "},{"type":"element","tagName":"span","properties":{"className":["gatsby-resp-image-background-image"],"style":"padding-bottom: 18.842530282637952%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABJ0AAASdAHeZh94AAAArElEQVQY002QXQ4CIQyE9/5XMTHGGE9ksutC6Q/6PE5ZMT40FJh+M7BE79DWICIwMzT2RylKKXB33h99RMCUGpbVinK+IKjtrxc6Oald9n2Hqv4A8gVmP8+UgDSshLg5jIPPdcXjcoWsG4xGw1gblhSmc67OhBOYaUWONQ1rqWMoNe6BRvh2u6MSLDOMVCwRfcSdlYD//XxKEDL2NO/vN4wG9XSG51eNdArl7AfrqS3dlW70JgAAAABJRU5ErkJggg=='); background-size: cover; display: block;"},"children":[]},{"type":"text","value":"\n    "},{"type":"element","tagName":"img","properties":{"className":["gatsby-resp-image-image"],"style":"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;box-shadow:inset 0px 0px 0px 400px white;","alt":"image tableau 2!","title":"","src":"/static/8642531b455ff7196ff3e4253ece2344/a8200/tab_example2.png","srcSet":["/static/8642531b455ff7196ff3e4253ece2344/52d5c/tab_example2.png 175w","/static/8642531b455ff7196ff3e4253ece2344/1bae2/tab_example2.png 350w","/static/8642531b455ff7196ff3e4253ece2344/a8200/tab_example2.png 700w","/static/8642531b455ff7196ff3e4253ece2344/ec5f3/tab_example2.png 743w"],"sizes":["(max-width:","700px)","100vw,","700px"]},"children":[]},{"type":"text","value":"\n  "}]},{"type":"text","value":"\n  "}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"En transformant chaque partition en tableaux de tableaux, on peut alors le donner en entrée de notre modèle et écouter les résultats joués rapidement par mes soins. (Désolé pour la mauvaise qualité audio et le manque de fluidité mais ces 'morceaux' ont été joués à leur découverte)."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Si les audios ne marchent pas sur votre navigateur, les fichiers sont disponibles "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/Tyrannas/n-grams-experiments/tree/master/audio"},"children":[{"type":"text","value":"ici"}]},{"type":"text","value":"."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=2"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"\n\t\t"},{"type":"element","tagName":"audio","properties":{"src":"/n2.mp3","preload":"auto","controls":true,"width":"undefined"},"children":[]},{"type":"text","value":"\n\t"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=3"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"\n\t\t"},{"type":"element","tagName":"audio","properties":{"src":"/n3.mp3","preload":"auto","controls":true,"width":"undefined"},"children":[]},{"type":"text","value":"\n\t"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour "},{"type":"element","tagName":"strong","properties":{},"children":[{"type":"text","value":"n=4"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"\n\t\t"},{"type":"element","tagName":"audio","properties":{"src":"/n4.mp3","preload":"auto","controls":true,"width":"undefined"},"children":[]},{"type":"text","value":"\n\t"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Cela reste en fin de compte assez expérimental mais peut être une potentielle source d'inspiration qui pourra être par la suite \"corrigée\" par le musicien pour que le résultat soit plus homogène!"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Pour aller plus loin"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Nous avons vu ici comme générer du contenu automatiquement à partir des modèles n-grammes. Aujourd'hui de nombreuses autres méthodes existent dans le monde de la création automatique (réseaux de neurones LSTM pour le texte, GAN pour l'image etc...). On pourra notamment penser à "},{"type":"element","tagName":"a","properties":{"href":"https://openai.com/blog/better-language-models/"},"children":[{"type":"text","value":"l'initiative Open AI"}]},{"type":"text","value":" qui a récemment produit des résultats assez impressionants sur la génération automatique d'article de journal à partir d'un simple résumé.\nCependant les n-grammes restent une solution très simple à mettre en place et pourtant assez robuste dans ses résultats (bien qu'ils soient plus utilisés comme support à d'autres algorithmes qu'utilisés de façon indépendante, voir 1.3)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Il existe malgré tout des moyens d'optimiser le modèle basique présenté ici. On pourrait par exemple entrainer des modèles avec des "},{"type":"element","tagName":"em","properties":{},"children":[{"type":"text","value":"n"}]},{"type":"text","value":" différents, puis essayer de les combiner. Il existe également des méthodes de smoothing, permettant d'homogénéiser les probabilités des mots prédits pour limiter l'overfit au texte. D'autres méthodes encore permettent de prendre en compte des mots jamais rencontrés lors de la prédiction..."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Une dernière piste d'amélioration et une critique majeure des n-grammes pourrait être celle de la sémantique. En effet si les n-grammes permettent de conserver une syntaxe assez cohérente, le sens lui même de la phrase générée n'est parfois pas cohérent. Si l'on reprend l'un de nos tous premiers exemples:"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"div","properties":{"className":["gatsby-highlight"],"dataLanguage":"text"},"children":[{"type":"element","tagName":"pre","properties":{"className":["language-text"]},"children":[{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"Il se fait tard et je suis fatigué."}]}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Même s'il existe effectivement des chances raisonnables de prédire fatigué avec seulement \"je suis\", la première partie de la phrase \"il se fait tard\" apporte un élément de sens non négligeable et qui pourrait fortement accroitre les probabilité d'avoir le mot \"fatigué\" en fin de phrase."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Pour pallier à ce problème des modèles tels que "},{"type":"element","tagName":"a","properties":{"href":"https://medium.com/nearist-ai/word2vec-tutorial-the-skip-gram-model-c7926e1fdc09"},"children":[{"type":"text","value":"word2vec"}]},{"type":"text","value":" qui construisent des représentations vectorielles des mots à partir du contexte de ces derniers. Plus précisémment, en utilisant non pas des n-grammes, mais des "},{"type":"element","tagName":"a","properties":{"href":"https://medium.com/nearist-ai/word2vec-tutorial-the-skip-gram-model-c7926e1fdc09"},"children":[{"type":"text","value":"skip-grammes!"}]},{"type":"text","value":" Cela permet de conserver l'aspect sémantique des phrases."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"On pourrait ainsi imaginer un système alliant n-grammes pour la syntaxe, et word2vec pour orienter le choix du mot à prédire."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Mais cela serait un sujet d'article à part entière. "}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Merci de votre lecture."}]}],"data":{"quirksMode":false}}},"tagRef":{"edges":[{"node":{"fields":{"slug":"/cas-d-usage-enjeux-marketing"},"frontmatter":{"tags":["data","machine learning"],"title":"Le Machine Learning pour la fonction Marketing","author":"Jérémy","excerpt":"Passage en revue des cas d'usage Marketing pour le ML","date":"17/07/2018"}}},{"node":{"fields":{"slug":"/generer-txt-music"},"frontmatter":{"tags":["machine learning"],"title":"Générer du texte et de la musique avec les modèles n-grammes","author":"Felix","excerpt":"Les n-grammes, modèles permettant de prédire des mots faisant suite à d'autres suites de mots","date":"30/09/2019"}}},{"node":{"fields":{"slug":"/meetup-deus"},"frontmatter":{"tags":["data","machine learning","meetup"],"title":"Meetup Code It Up: Deus Ex Machine Learning","author":"Matthieu","excerpt":"Comprendre le machine learning sans hashtag","date":"30/03/2018"}}},{"node":{"fields":{"slug":"/mario-neural-network"},"frontmatter":{"tags":["data","machine learning","atelier"],"title":"Mario Neural Network","author":"Clément","excerpt":"Finir le premier niveau de Super Mario Bros. 1 de façon automatique à l'aide d'un neural network","date":"09/07/2018"}}},{"node":{"fields":{"slug":"/meetup-mario-nn"},"frontmatter":{"tags":["data","machine learning","meetup"],"title":"Meetup Code It Up: Mario Neural Network","author":"Matthieu","excerpt":"Le meetup qui a cassé des briques","date":"01/07/2018"}}},{"node":{"fields":{"slug":"/natural-language-processing"},"frontmatter":{"tags":["data","machine learning"],"title":"Introduction au NLP : le traitement de texte automatisé","author":"Team Data","excerpt":"Découvrez les étapes de pré-processing de texte pour maîtriser vos projets de NLP","date":"17/10/2018"}}}]},"infoAuthor":{"edges":[{"node":{"frontmatter":{"title":"Artisan web et data","author":"Felix","date":"2019-01-21","excerpt":"Une phrase au hasard","illustration":{"childImageSharp":{"resize":{"src":"/static/db692b8bbe5ee0d12a8c5aa2c3ca6fc6/28898/cover.png"}}}},"fields":{"slug":"/felix"}}}]}},"pageContext":{"isCreatedByStatefulCreatePages":false,"slug":"/generer-txt-music","tags":["machine learning"],"author":"Felix"}}